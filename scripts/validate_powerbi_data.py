import os
import yaml
import glob
import pandas as pd
import pyarrow.parquet as pq

# ğŸ“‚ Carregar ConfiguraÃ§Ã£o do YAML
config_path = os.path.abspath("config/config.yaml")

if not os.path.exists(config_path):
    raise FileNotFoundError("âŒ Arquivo 'config.yaml' nÃ£o encontrado!")

with open(config_path, "r") as f:
    config = yaml.safe_load(f)

# ğŸ“‚ Definir diretÃ³rio dos dados otimizados
OPTIMIZED_DATA_DIR = os.path.abspath(config.get("optimized_data_path", "data/optimized/"))

# ğŸ“‚ Buscar arquivos Parquet (incluindo subdiretÃ³rios)
parquet_files = glob.glob(os.path.join(OPTIMIZED_DATA_DIR, "**", "*.parquet"), recursive=True)

# ğŸš€ Verificar se encontrou arquivos Parquet
if not parquet_files:
    raise FileNotFoundError(f"âŒ Nenhum arquivo Parquet encontrado em '{OPTIMIZED_DATA_DIR}'.")

print(f"âœ… {len(parquet_files)} arquivos Parquet encontrados.")

# ğŸ“Œ Ler todos os Parquets e consolidar no Pandas
df_list = []
for file in parquet_files:
    print(f"ğŸ“‚ Lendo: {file}")
    df_list.append(pq.read_table(file).to_pandas())

# ğŸ”„ Concatenar todos os DataFrames
df = pd.concat(df_list, ignore_index=True)

# ğŸ“Š Exibir estatÃ­sticas bÃ¡sicas
print(df.head())
print(df.describe())
print(df.dtypes)



# ğŸ“‚ Definir caminho para o CSV final
CSV_OUTPUT_PATH = os.path.abspath("data/powerbi_data.csv")

# ğŸš€ Salvar como CSV
df.to_csv(CSV_OUTPUT_PATH, index=False, encoding="utf-8")
print(f"âœ… Arquivo CSV salvo em: {CSV_OUTPUT_PATH}")

print("ğŸš€ Processo concluÃ­do!")
