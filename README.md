# **AWS Glue & PySpark ETL**

## ğŸ“Œ **Objetivo**
Este projeto implementa um **pipeline de ETL escalÃ¡vel** usando **AWS Glue e PySpark** para processamento, transformaÃ§Ã£o e validaÃ§Ã£o de dados transacionais.  

AlÃ©m das etapas tradicionais de ETL, este projeto se destaca por:  
âœ… **OtimizaÃ§Ã£o de consultas SQL e PySpark** para melhor performance.  
âœ… **ComparaÃ§Ã£o entre diferentes abordagens** (SQL puro vs. PySpark vs. Delta Lake).  
âœ… **CriaÃ§Ã£o de um dataset otimizado para Power BI** e anÃ¡lise de fraudes financeiras.  
âœ… **ExecuÃ§Ã£o do ETL validada tanto no VS Code (Spark Standalone) quanto no Jupyter.**  

---

## ğŸ”¹ **Fonte dos Dados**
Os dados vÃªm de um dataset pÃºblico do Kaggle, gerado pelo **Sparkov Data Generation**, simulando transaÃ§Ãµes financeiras de **janeiro a dezembro de 2023**.

### ğŸ“Œ **Dataset**:
[Kaggle - Fraude em TransaÃ§Ãµes de CartÃ£o de CrÃ©dito](https://www.kaggle.com/competitions/fraude-em-transaes-de-carto-de-crdito/data)

**Principais colunas:**
- **Dados da transaÃ§Ã£o:** Data, valor (`amt`), comerciante (`merchant`), categoria (`category`).
- **Dados do cliente:** Nome, localizaÃ§Ã£o, gÃªnero, profissÃ£o.
- **Sinalizador de fraude (`is_fraud`).**

---

## ğŸ”¹ **Tecnologias Utilizadas**
ğŸ’¾ **Processamento e TransformaÃ§Ã£o**  
âœ… **AWS Glue & PySpark** â†’ Para manipulaÃ§Ã£o de grandes volumes de dados.  
âœ… **SQL (AWS Athena)** â†’ Para consultas eficientes e validaÃ§Ã£o de dados.  

ğŸ“Š **AnÃ¡lise e VisualizaÃ§Ã£o**  
âœ… **Jupyter Notebook** â†’ Para anÃ¡lise exploratÃ³ria e experimentaÃ§Ã£o com consultas otimizadas.  
âœ… **Power BI** â†’ Para construÃ§Ã£o de **dashboards interativos** sobre fraudes.  

ğŸš€ **Armazenamento e IntegraÃ§Ã£o**  
âœ… **AWS S3** â†’ Para armazenamento eficiente dos dados.  
âœ… **Parquet & Delta Lake** â†’ Formatos otimizados para leitura rÃ¡pida no Power BI.  

---

## ğŸš€ **Pipeline de ETL e OtimizaÃ§Ãµes**
ğŸ”¹ **1ï¸âƒ£ ExtraÃ§Ã£o** â†’ Carregamento do dataset bruto (CSV).  
ğŸ”¹ **2ï¸âƒ£ TransformaÃ§Ã£o (ETL no PySpark)**
   - **RemoÃ§Ã£o de nulos e duplicatas.**
   - **DetecÃ§Ã£o e remoÃ§Ã£o de outliers com Z-score.**
   - **ConversÃ£o do schema para garantir consistÃªncia (ex: FLOAT â†’ DOUBLE).**
   - **CriaÃ§Ã£o de novas colunas Ãºteis (hora, perÃ­odo do dia, tempo entre transaÃ§Ãµes).**
   - **ComparaÃ§Ã£o entre SQL puro, PySpark e Delta Lake.**
ğŸ”¹ **3ï¸âƒ£ Salvamento e OtimizaÃ§Ã£o**
   - **Formato Parquet** â†’ Arquivo leve e eficiente para anÃ¡lise.
   - **Delta Lake** â†’ Para suporte a updates incrementais.
   - **ComparaÃ§Ã£o entre modos de escrita e impacto na performance.**
ğŸ”¹ **4ï¸âƒ£ AnÃ¡lise e RelatÃ³rios**
   - **Dashboards no Power BI** conectados diretamente ao dataset otimizado.

---

## ğŸ“Š **OtimizaÃ§Ã£o de Consultas SQL e PySpark**
- **ğŸ”¥ Teste de performance:** Tempo de execuÃ§Ã£o com SQL puro vs. PySpark.
- **ğŸ“ˆ EstratÃ©gias aplicadas para reduzir tempo de leitura:**
  âœ… **ConversÃ£o de FLOAT para DOUBLE** antes do salvamento em Parquet.  
  âœ… **Uso de particionamento inteligente** (`partitionBy("category")`).  
  âœ… **Reparticionamento do DataFrame para paralelismo eficiente** (`df.repartition(4)`).  
  âœ… **ComparaÃ§Ã£o entre Parquet e Delta Lake** em termos de eficiÃªncia.  

---

## ğŸ”¹ **Formato do Arquivo Final para Power BI**
| Formato | Motivo |
|---------|--------|
| **Parquet** | ğŸš€ CompactaÃ§Ã£o melhor e leitura rÃ¡pida no Power BI. |
| **Delta Lake** | ğŸ”„ Permite atualizaÃ§Ãµes incrementais nos dados. |
| **CSV** | âŒ NÃ£o utilizado, pois ocupa mais espaÃ§o e tem leitura lenta. |

ğŸ“Œ **DecisÃ£o final:**  
- O **Parquet foi escolhido** para o dataset final devido Ã  **eficiÃªncia de leitura** no Power BI.  
- Caso seja necessÃ¡rio **atualizaÃ§Ãµes incrementais**, a versÃ£o **Delta Lake** pode ser ativada.

---

## ğŸ”¹ **Estrutura do Projeto**

aws-glue-pyspark-etl/
â”œâ”€â”€ data/                          # Dados brutos e processados
â”œâ”€â”€ notebooks/                      # Jupyter Notebook para anÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb   # AnÃ¡lise exploratÃ³ria, otimizaÃ§Ã£o e insights
â”œâ”€â”€ scripts/                        # CÃ³digo ETL em Python (VS Code)
â”œâ”€â”€ power_bi/                        # Dashboard Power BI
â”œâ”€â”€ config/                         
â”‚   â”œâ”€â”€ schema.json                 # DefiniÃ§Ã£o do schema dos dados
â”‚   â”œâ”€â”€ settings.yaml                # ConfiguraÃ§Ãµes gerais
â””â”€â”€ README.md                        # DocumentaÃ§Ã£o do projeto

---

## ğŸ“Š **Resultados e Insights**
âœ… **Melhoria de performance nas consultas** apÃ³s conversÃ£o e otimizaÃ§Ã£o.  
âœ… **Arquivos otimizados em Parquet**, reduzindo tempo de carregamento no Power BI.  
âœ… **Dashboards interativos** analisando padrÃµes de fraudes em transaÃ§Ãµes.  

ğŸš€ **TÃ©cnicas aplicadas para acelerar consultas**  
- **Particionamento correto dos dados** (`partitionBy("category")`).  
- **Uso de formatos eficientes** para integraÃ§Ã£o com Power BI.  
- **ComparaÃ§Ã£o de estratÃ©gias de escrita e impacto na performance.**  

---

## ğŸ“” **Notebooks Criados**
1. **01_data_exploration.ipynb** â†’ **ExploraÃ§Ã£o, validaÃ§Ã£o e otimizaÃ§Ã£o do dataset**.  

ğŸ“Œ **Diferente de projetos convencionais**, **toda a etapa de ETL foi validada no VS Code** para garantir um fluxo de dados escalÃ¡vel e eficiente, enquanto **o notebook foca na anÃ¡lise e otimizaÃ§Ã£o de consultas para exploraÃ§Ã£o dos dados**.

---

## ğŸ”„ **PrÃ³ximos Passos**
âœ… **Testar Delta Lake para atualizaÃ§Ã£o incremental.**  
âœ… **Criar um relatÃ³rio mais avanÃ§ado no Power BI.**  
âœ… **Adicionar logs e monitoramento da performance do ETL.**  
âœ… **Testar diferentes tamanhos de partiÃ§Ãµes e impacto no carregamento do Power BI.**  

---

ğŸ“Œ **Desenvolvido por** [Viviana](https://github.com/vivinfor)  
