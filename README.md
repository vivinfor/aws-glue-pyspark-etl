# **AWS Glue, PySpark & FastAPI ETL**

## ğŸ“Œ **Objetivo**
Este projeto implementa um **pipeline de ETL escalÃ¡vel** combinando **AWS Glue, PySpark e FastAPI** para processamento, transformaÃ§Ã£o e disponibilizaÃ§Ã£o de dados transacionais.

AlÃ©m das etapas tradicionais de ETL, este projeto se destaca por:  
âœ… **OtimizaÃ§Ã£o de consultas SQL e PySpark** para melhor performance.  
âœ… **Uso de uma abordagem hÃ­brida** â†’ **Banco de dados para mÃ©tricas calculadas** e **Parquet para armazenar dados brutos e histÃ³ricos**.  
âœ… **ExposiÃ§Ã£o de dados via FastAPI**, centralizando cÃ¡lculos no backend para evitar inconsistÃªncias.  
âœ… **CriaÃ§Ã£o de um dataset otimizado para Power BI** e anÃ¡lise de fraudes financeiras.  
âœ… **ExecuÃ§Ã£o do ETL validada tanto no VS Code (Spark Standalone) quanto no Jupyter.**  

---

## ğŸ‘‰ **Origem e Estrutura dos Dados**

Este projeto foi desenvolvido para processar e otimizar **transaÃ§Ãµes financeiras fictÃ­cias**, aplicando regras de validaÃ§Ã£o e detecÃ§Ã£o de fraudes para garantir a qualidade dos dados antes da anÃ¡lise.

### ğŸ“š **Estrutura dos Dados**

Os dados sÃ£o estruturados para incluir:

âœ… **Detalhes da transaÃ§Ã£o** â†’ Data, valor (`amt`), comerciante (`merchant`), categoria (`category`).  
âœ… **InformaÃ§Ãµes do cliente** â†’ LocalizaÃ§Ã£o, profissÃ£o, identificador Ãºnico.  
âœ… **SinalizaÃ§Ã£o de fraudes** â†’ IdentificaÃ§Ã£o de padrÃµes suspeitos para anÃ¡lise posterior.  

### ğŸ‘€ **Foco do Projeto**

Este projeto nÃ£o se trata apenas de carregar um conjunto de dados, mas sim de **demonstrar boas prÃ¡ticas de ETL, otimizaÃ§Ã£o de dados e criaÃ§Ã£o de insights estruturados para anÃ¡lise de fraudes**.

ğŸ’¡ **Importante:** O pipeline foi projetado para garantir **coerÃªncia e integridade** nas informaÃ§Ãµes processadas, aplicando validaÃ§Ãµes antes da carga e garantindo que os dados analisados sejam consistentes com as regras de negÃ³cio definidas.

---

## ğŸ”¹ **Tecnologias Utilizadas**
ğŸ’¾ **Processamento e TransformaÃ§Ã£o**  
âœ… **AWS Glue & PySpark** â†’ Para manipulaÃ§Ã£o de grandes volumes de dados.  
âœ… **SQL (AWS Athena)** â†’ Para consultas eficientes e validaÃ§Ã£o de dados.  

ğŸ“Š **AnÃ¡lise e VisualizaÃ§Ã£o**  
âœ… **Jupyter Notebook** â†’ Para anÃ¡lise exploratÃ³ria e experimentaÃ§Ã£o com consultas otimizadas.  
âœ… **Power BI** â†’ Para construÃ§Ã£o de **dashboards interativos** sobre fraudes.  
âœ… **FastAPI** â†’ ExposiÃ§Ã£o dos cÃ¡lculos como API para garantir consistÃªncia.  

ğŸš€ **Armazenamento e IntegraÃ§Ã£o**  
âœ… **AWS S3 + Parquet** â†’ Para armazenamento eficiente dos dados brutos e histÃ³ricos.  
âœ… **PostgreSQL** â†’ Para armazenamento de mÃ©tricas prÃ©-calculadas e acesso rÃ¡pido na API.  
âœ… **Delta Lake** â†’ Suporte a atualizaÃ§Ãµes incrementais.  

---

## ğŸš€ **Arquitetura HÃ­brida (Parquet + Banco de Dados + API)**

Este projeto adota uma **abordagem hÃ­brida**, combinando **Parquet, banco de dados e API** para maximizar desempenho e escalabilidade:

1ï¸âƒ£ **Parquet (AWS S3 / Local)** â†’ Armazena **dados brutos e histÃ³ricos** otimizados para leitura no Power BI.  
2ï¸âƒ£ **PostgreSQL** â†’ Centraliza **mÃ©tricas calculadas**, garantindo performance para anÃ¡lises frequentes.  
3ï¸âƒ£ **FastAPI** â†’ ExpÃµe **dados prÃ©-processados** para evitar cÃ¡lculos repetitivos no Power BI.  

### **ğŸ“Œ Vantagens da Arquitetura**
âœ… **CentralizaÃ§Ã£o dos cÃ¡lculos no Python** evita inconsistÃªncias entre usuÃ¡rios.  
âœ… **Banco de Dados para mÃ©tricas** â†’ Respostas rÃ¡pidas via API, reduzindo processamento no Power BI.  
âœ… **Parquet para histÃ³rico** â†’ MantÃ©m dados brutos disponÃ­veis para consultas avanÃ§adas.  
âœ… **API padronizada** â†’ IntegraÃ§Ãµes consistentes entre aplicaÃ§Ãµes e anÃ¡lises de negÃ³cio.  

---

## ğŸš€ **Endpoints da API FastAPI**
A API expÃµe mÃ©tricas **prÃ©-calculadas**, reduzindo a carga computacional no Power BI e padronizando cÃ¡lculos.  

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|---------|------------|
| **GET** | `/transactions/summary` | Retorna total de transaÃ§Ãµes, fraudes e mÃ©dia de valores. |
| **GET** | `/fraud/monthly` | Retorna o total de fraudes por mÃªs. |
| **GET** | `/fraud/category` | Retorna fraudes agregadas por categoria de transaÃ§Ã£o. |
| **GET** | `/fraud/high_value` | Lista transaÃ§Ãµes suspeitas acima de $10.000. |
| **GET** | `/anomalies/outliers` | Identifica transaÃ§Ãµes com valores fora do padrÃ£o. |

**Exemplo de Uso:**
```sh
curl -X GET "http://localhost:8000/transactions/summary"
```

---

## ğŸ“Š **Formato do Arquivo Final para Power BI**
| Formato | Motivo |
|---------|--------|
| **Parquet** | ğŸš€ CompactaÃ§Ã£o melhor e leitura rÃ¡pida no Power BI. |
| **PostgreSQL** | ğŸ”„ Permite armazenamento de mÃ©tricas calculadas para acesso via API. |
| **CSV** | âŒ NÃ£o utilizado, pois ocupa mais espaÃ§o e tem leitura lenta. |

ğŸ“Œ **DecisÃ£o final:**  
- **API FastAPI + PostgreSQL** para mÃ©tricas acessadas com frequÃªncia.  
- **Parquet para armazenamento de dados histÃ³ricos e carregamento no Power BI.**  

---

## ğŸ‘‰ Estrutura do Projeto

```md
aws-glue-pyspark-etl/
â”œâ”€â”€ data/                  # Dados brutos e processados
â”œâ”€â”€ notebooks/             # Jupyter Notebook para anÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb  # AnÃ¡lise exploratÃ³ria, otimizaÃ§Ã£o e insights
â”œâ”€â”€ scripts/               # CÃ³digo ETL em Python (VS Code)
â”œâ”€â”€ api/                   # ImplementaÃ§Ã£o da API FastAPI
â”œâ”€â”€ power_bi/              # Dashboard Power BI
â”œâ”€â”€ config/                
â”‚   â”œâ”€â”€ schema.json        # DefiniÃ§Ã£o do schema dos dados
â”‚   â”œâ”€â”€ settings.yaml      # ConfiguraÃ§Ãµes gerais
â””â”€â”€ README.md              # DocumentaÃ§Ã£o do projeto
```

---

## ğŸ”„ **PrÃ³ximos Passos**
âœ… **ImplementaÃ§Ã£o da API**  para expor mÃ©tricas calculadas, garantindo acesso rÃ¡pido e estruturado aos dados.
âœ… **Monitoramento da API** para acompanhar tempo de resposta e acessos.  
âœ… **CriaÃ§Ã£o de uma camada de cache (Redis) para reduzir consultas repetitivas.**  
âœ… **Aprimorar detecÃ§Ã£o de anomalias com aprendizado de mÃ¡quina.**  
âœ… **Testar escalabilidade com maior volume de dados.**  
âœ… **Criar documentaÃ§Ã£o completa para consumo da API.**  

---

ğŸ“Œ **Desenvolvido por** [Viviana](https://github.com/vivinfor) ğŸš€

